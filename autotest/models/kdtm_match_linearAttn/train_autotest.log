2019-05-26 07:10:45,516 DEBUG ModelConf.py load_from_file 128: Prepare dir for: ./autotest/models/kdtm_match_linearAttn/predict.tsv
2019-05-26 07:10:46,074 INFO ModelConf.py load_from_file 349: Activating GPU mode, there are 1 GPUs available
2019-05-26 07:10:46,074 DEBUG ModelConf.py __init__ 45: Print ModelConf below:
2019-05-26 07:10:46,075 DEBUG ModelConf.py __init__ 46: ================================================================================
2019-05-26 07:10:46,075 DEBUG ModelConf.py __init__ 50: phase: train
2019-05-26 07:10:46,075 DEBUG ModelConf.py __init__ 50: conf_path: autotest/conf/conf_kdtm_match_linearAttn_autotest.json
2019-05-26 07:10:46,075 DEBUG ModelConf.py __init__ 50: params: Namespace(batch_size=None, cache_dir=None, conf_path='autotest/conf/conf_kdtm_match_linearAttn_autotest.json', debug=False, disable_log_file=False, force=True, involve_all_words_in_pretrained_emb=False, learning_rate=None, log_dir=None, make_cache_only=False, max_epoch=None, mode='normal', model_save_dir=None, predict_output_path=None, pretrained_emb_binary_or_text='text', pretrained_emb_path=None, pretrained_emb_type='glove', pretrained_model_path=None, test_data_path=None, train_data_path=None, valid_data_path=None)
2019-05-26 07:10:46,075 DEBUG ModelConf.py __init__ 50: mode: normal
2019-05-26 07:10:46,076 DEBUG ModelConf.py __init__ 50: conf: {'license': 'Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT license.', 'tool_version': '1.1.0', 'model_description': 'This model is used for model compression', 'inputs': {'use_cache': True, 'dataset_type': 'regression', 'data_paths': {'train_data_path': './autotest/dataset/knowledge_distillation/text_matching_data/train_autotest.tsv', 'valid_data_path': './autotest/dataset/knowledge_distillation/text_matching_data/valid.tsv', 'test_data_path': './autotest/dataset/knowledge_distillation/text_matching_data/test.tsv', 'pre_trained_emb': 'dataset/GloVe/glove.840B.300d.txt'}, 'add_start_end_for_seq': True, 'file_header': {'query_text': 0, 'passage_text': 1, 'label_score': 2}, 'predict_file_header': {'query_text': 0, 'passage_text': 1}, 'model_inputs': {'query': ['query_text'], 'passage': ['passage_text']}, 'target': ['label_score']}, 'outputs': {'save_base_dir': './autotest/models/kdtm_match_linearAttn/', 'model_name': 'model.nb', 'train_log_name': 'train_autotest.log', 'test_log_name': 'test_autotest.log', 'predict_log_name': 'predict.log', 'predict_fields': ['prediction'], 'predict_output_name': 'predict.tsv', 'cache_dir': '.cache.kdtm_match_linearAttn/'}, 'training_params': {'vocabulary': {'min_word_frequency': 1}, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.2, 'momentum': 0.9, 'nesterov': True}}, 'lr_decay': 0.95, 'minimum_lr': 0.005, 'epoch_start_lr_decay': 1, 'use_gpu': True, 'batch_size': 128, 'batch_num_to_show_results': 100, 'max_epoch': 10, 'valid_times_per_epoch': 2, 'max_lengths': {'query': 30, 'passage': 200}}, 'architecture': [{'layer': 'Embedding', 'conf': {'word': {'cols': ['query_text', 'passage_text'], 'dim': 300}}}, {'layer_id': 'query_dropout', 'layer': 'Dropout', 'conf': {'dropout': 0.3}, 'inputs': ['query']}, {'layer_id': 'passage_dropout', 'layer': 'Dropout', 'conf': {'dropout': 0.3}, 'inputs': ['passage']}, {'layer_id': 'query_1', 'layer': 'BiLSTM', 'conf': {'hidden_dim': 128, 'dropout': 0.3, 'num_layers': 3}, 'inputs': ['query_dropout']}, {'layer_id': 'passage_matched', 'layer': 'MatchAttention', 'conf': {}, 'inputs': ['passage_dropout', 'query_dropout']}, {'layer_id': 'passage_combined', 'layer': 'Combination', 'conf': {'operations': ['origin']}, 'inputs': ['passage_dropout', 'passage_matched']}, {'layer_id': 'passage_1', 'layer': 'BiLSTM', 'conf': {'hidden_dim': 128, 'dropout': 0.3, 'num_layers': 3}, 'inputs': ['passage_combined']}, {'layer_id': 'query_linear_att', 'layer': 'LinearAttention', 'conf': {'attention_weight_dim': 256, 'keep_dim': False}, 'inputs': ['query_1']}, {'layer_id': 'passage_linear_att', 'layer': 'LinearAttention', 'conf': {'attention_weight_dim': 256, 'keep_dim': False}, 'inputs': ['passage_1']}, {'layer_id': 'comb', 'layer': 'Combination', 'conf': {'operations': ['origin']}, 'inputs': ['query_linear_att', 'passage_linear_att']}, {'layer_id': 'linear', 'layer': 'Linear', 'conf': {'hidden_dim': [512], 'activation': 'PReLU', 'batch_norm': True, 'last_hidden_activation': True}, 'inputs': ['comb']}, {'output_layer_flag': True, 'layer_id': 'output', 'layer': 'Linear', 'conf': {'hidden_dim': [1], 'activation': 'Sigmoid', 'last_hidden_activation': True, 'last_hidden_softmax': False}, 'inputs': ['linear']}], 'loss': {'losses': [{'type': 'MSELoss', 'conf': {}, 'inputs': ['output', 'label_score']}]}, 'metrics': ['RMSE', 'MSE']}
2019-05-26 07:10:46,076 DEBUG ModelConf.py __init__ 50: tool_version: 1.1.0
2019-05-26 07:10:46,076 DEBUG ModelConf.py __init__ 50: language: english
2019-05-26 07:10:46,076 DEBUG ModelConf.py __init__ 50: problem_type: regression
2019-05-26 07:10:46,076 DEBUG ModelConf.py __init__ 50: use_cache: True
2019-05-26 07:10:46,076 DEBUG ModelConf.py __init__ 50: save_base_dir: ./autotest/models/kdtm_match_linearAttn/
2019-05-26 07:10:46,076 DEBUG ModelConf.py __init__ 50: pretrained_model_path: None
2019-05-26 07:10:46,076 DEBUG ModelConf.py __init__ 50: previous_model_path: None
2019-05-26 07:10:46,076 DEBUG ModelConf.py __init__ 50: log_dir: ./autotest/models/kdtm_match_linearAttn/
2019-05-26 07:10:46,077 DEBUG ModelConf.py __init__ 50: train_log_path: ./autotest/models/kdtm_match_linearAttn/train_autotest.log
2019-05-26 07:10:46,077 DEBUG ModelConf.py __init__ 50: predict_output_path: ./autotest/models/kdtm_match_linearAttn/predict.tsv
2019-05-26 07:10:46,077 DEBUG ModelConf.py __init__ 50: predict_fields: ['prediction']
2019-05-26 07:10:46,077 DEBUG ModelConf.py __init__ 50: model_save_path: ./autotest/models/kdtm_match_linearAttn/model.nb
2019-05-26 07:10:46,077 DEBUG ModelConf.py __init__ 50: train_data_path: ./autotest/dataset/knowledge_distillation/text_matching_data/train_autotest.tsv
2019-05-26 07:10:46,077 DEBUG ModelConf.py __init__ 50: valid_data_path: ./autotest/dataset/knowledge_distillation/text_matching_data/valid.tsv
2019-05-26 07:10:46,077 DEBUG ModelConf.py __init__ 50: test_data_path: ./autotest/dataset/knowledge_distillation/text_matching_data/test.tsv
2019-05-26 07:10:46,077 DEBUG ModelConf.py __init__ 50: file_columns: {'query_text': 0, 'passage_text': 1, 'label_score': 2}
2019-05-26 07:10:46,077 DEBUG ModelConf.py __init__ 50: answer_column_name: ['label_score']
2019-05-26 07:10:46,077 DEBUG ModelConf.py __init__ 50: input_types: {'word': {'cols': ['query_text', 'passage_text'], 'dim': 300}}
2019-05-26 07:10:46,077 DEBUG ModelConf.py __init__ 50: extra_feature: False
2019-05-26 07:10:46,077 DEBUG ModelConf.py __init__ 50: object_inputs: {'query': ['query_text'], 'passage': ['passage_text']}
2019-05-26 07:10:46,078 DEBUG ModelConf.py __init__ 50: object_inputs_names: ['query', 'passage']
2019-05-26 07:10:46,078 DEBUG ModelConf.py __init__ 50: max_vocabulary: 800000
2019-05-26 07:10:46,078 DEBUG ModelConf.py __init__ 50: min_word_frequency: 1
2019-05-26 07:10:46,078 DEBUG ModelConf.py __init__ 50: file_with_col_header: False
2019-05-26 07:10:46,078 DEBUG ModelConf.py __init__ 50: add_start_end_for_seq: True
2019-05-26 07:10:46,078 DEBUG ModelConf.py __init__ 50: pretrained_emb_path: dataset/GloVe/glove.840B.300d.txt
2019-05-26 07:10:46,078 DEBUG ModelConf.py __init__ 50: involve_all_words_in_pretrained_emb: False
2019-05-26 07:10:46,078 DEBUG ModelConf.py __init__ 50: pretrained_emb_type: glove
2019-05-26 07:10:46,078 DEBUG ModelConf.py __init__ 50: pretrained_emb_binary_or_text: text
2019-05-26 07:10:46,078 DEBUG ModelConf.py __init__ 50: pretrained_emb_dim: 300
2019-05-26 07:10:46,078 DEBUG ModelConf.py __init__ 50: cache_dir: .cache.kdtm_match_linearAttn/
2019-05-26 07:10:46,078 DEBUG ModelConf.py __init__ 50: problem_path: .cache.kdtm_match_linearAttn/problem.pkl
2019-05-26 07:10:46,078 DEBUG ModelConf.py __init__ 50: emb_pkl_path: .cache.kdtm_match_linearAttn/emb.pkl
2019-05-26 07:10:46,078 DEBUG ModelConf.py __init__ 50: training_params: {'vocabulary': {'min_word_frequency': 1}, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.2, 'momentum': 0.9, 'nesterov': True}}, 'lr_decay': 0.95, 'minimum_lr': 0.005, 'epoch_start_lr_decay': 1, 'use_gpu': True, 'batch_size': 128, 'batch_num_to_show_results': 100, 'max_epoch': 10, 'valid_times_per_epoch': 2, 'max_lengths': {'query': 30, 'passage': 200}}
2019-05-26 07:10:46,079 DEBUG ModelConf.py __init__ 50: optimizer_name: SGD
2019-05-26 07:10:46,079 DEBUG ModelConf.py __init__ 50: optimizer_params: {'lr': 0.2, 'momentum': 0.9, 'nesterov': True}
2019-05-26 07:10:46,079 DEBUG ModelConf.py __init__ 50: clip_grad_norm_max_norm: 5
2019-05-26 07:10:46,079 DEBUG ModelConf.py __init__ 50: batch_size_each_gpu: 128
2019-05-26 07:10:46,079 DEBUG ModelConf.py __init__ 50: lr_decay: 0.95
2019-05-26 07:10:46,079 DEBUG ModelConf.py __init__ 50: minimum_lr: 0.005
2019-05-26 07:10:46,079 DEBUG ModelConf.py __init__ 50: epoch_start_lr_decay: 1
2019-05-26 07:10:46,079 DEBUG ModelConf.py __init__ 50: max_epoch: 10
2019-05-26 07:10:46,079 DEBUG ModelConf.py __init__ 50: valid_times_per_epoch: 2
2019-05-26 07:10:46,079 DEBUG ModelConf.py __init__ 50: batch_num_to_show_results: 100
2019-05-26 07:10:46,079 DEBUG ModelConf.py __init__ 50: max_lengths: {'query': 30, 'passage': 200}
2019-05-26 07:10:46,079 DEBUG ModelConf.py __init__ 50: fixed_lengths: None
2019-05-26 07:10:46,079 DEBUG ModelConf.py __init__ 50: batch_size_total: 128
2019-05-26 07:10:46,079 DEBUG ModelConf.py __init__ 50: cpu_num_workers: -1
2019-05-26 07:10:46,080 DEBUG ModelConf.py __init__ 50: _ModelConf__text_preprocessing: []
2019-05-26 07:10:46,080 DEBUG ModelConf.py __init__ 50: DBC2SBC: False
2019-05-26 07:10:46,080 DEBUG ModelConf.py __init__ 50: unicode_fix: False
2019-05-26 07:10:46,080 DEBUG ModelConf.py __init__ 50: remove_stopwords: False
2019-05-26 07:10:46,080 DEBUG ModelConf.py __init__ 50: tokenizer: nltk
2019-05-26 07:10:46,080 DEBUG ModelConf.py __init__ 50: use_gpu: True
2019-05-26 07:10:46,080 DEBUG ModelConf.py __init__ 50: architecture: [{'layer': 'Embedding', 'conf': {'word': {'cols': ['query_text', 'passage_text'], 'dim': 300}}}, {'layer_id': 'query_dropout', 'layer': 'Dropout', 'conf': {'dropout': 0.3}, 'inputs': ['query']}, {'layer_id': 'passage_dropout', 'layer': 'Dropout', 'conf': {'dropout': 0.3}, 'inputs': ['passage']}, {'layer_id': 'query_1', 'layer': 'BiLSTM', 'conf': {'hidden_dim': 128, 'dropout': 0.3, 'num_layers': 3}, 'inputs': ['query_dropout']}, {'layer_id': 'passage_matched', 'layer': 'MatchAttention', 'conf': {}, 'inputs': ['passage_dropout', 'query_dropout']}, {'layer_id': 'passage_combined', 'layer': 'Combination', 'conf': {'operations': ['origin']}, 'inputs': ['passage_dropout', 'passage_matched']}, {'layer_id': 'passage_1', 'layer': 'BiLSTM', 'conf': {'hidden_dim': 128, 'dropout': 0.3, 'num_layers': 3}, 'inputs': ['passage_combined']}, {'layer_id': 'query_linear_att', 'layer': 'LinearAttention', 'conf': {'attention_weight_dim': 256, 'keep_dim': False}, 'inputs': ['query_1']}, {'layer_id': 'passage_linear_att', 'layer': 'LinearAttention', 'conf': {'attention_weight_dim': 256, 'keep_dim': False}, 'inputs': ['passage_1']}, {'layer_id': 'comb', 'layer': 'Combination', 'conf': {'operations': ['origin']}, 'inputs': ['query_linear_att', 'passage_linear_att']}, {'layer_id': 'linear', 'layer': 'Linear', 'conf': {'hidden_dim': [512], 'activation': 'PReLU', 'batch_norm': True, 'last_hidden_activation': True}, 'inputs': ['comb']}, {'output_layer_flag': True, 'layer_id': 'output', 'layer': 'Linear', 'conf': {'hidden_dim': [1], 'activation': 'Sigmoid', 'last_hidden_activation': True, 'last_hidden_softmax': False}, 'inputs': ['linear']}]
2019-05-26 07:10:46,080 DEBUG ModelConf.py __init__ 50: output_layer_id: ['output']
2019-05-26 07:10:46,080 DEBUG ModelConf.py __init__ 50: min_sentence_len: 0
2019-05-26 07:10:46,080 DEBUG ModelConf.py __init__ 50: loss: {'losses': [{'type': 'MSELoss', 'conf': {}, 'inputs': ['output', 'label_score']}], 'multiLoss': False}
2019-05-26 07:10:46,080 DEBUG ModelConf.py __init__ 50: metrics: ['RMSE', 'MSE']
2019-05-26 07:10:46,080 DEBUG ModelConf.py __init__ 50: metrics_post_check: set()
2019-05-26 07:10:46,081 DEBUG ModelConf.py __init__ 51: ================================================================================
2019-05-26 07:10:46,081 INFO train.py main 52: Configuration file is backed up to ./autotest/models/kdtm_match_linearAttn/
2019-05-26 07:10:46,082 DEBUG ModelConf.py __init__ 45: Print ModelConf below:
2019-05-26 07:10:46,082 DEBUG ModelConf.py __init__ 46: ================================================================================
2019-05-26 07:10:46,082 DEBUG ModelConf.py __init__ 50: phase: cache
2019-05-26 07:10:46,083 DEBUG ModelConf.py __init__ 50: conf_path: .cache.kdtm_match_linearAttn/conf_cache.json
2019-05-26 07:10:46,083 DEBUG ModelConf.py __init__ 50: params: Namespace(batch_size=None, cache_dir=None, conf_path='autotest/conf/conf_kdtm_match_linearAttn_autotest.json', debug=False, disable_log_file=False, force=True, involve_all_words_in_pretrained_emb=False, learning_rate=None, log_dir=None, make_cache_only=False, max_epoch=None, mode='normal', model_save_dir=None, predict_output_path=None, pretrained_emb_binary_or_text='text', pretrained_emb_path=None, pretrained_emb_type='glove', pretrained_model_path=None, test_data_path=None, train_data_path=None, valid_data_path=None)
2019-05-26 07:10:46,083 DEBUG ModelConf.py __init__ 50: mode: normal
2019-05-26 07:10:46,083 DEBUG ModelConf.py __init__ 50: conf: {'license': 'Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT license.', 'tool_version': '1.1.0', 'model_description': 'This model is used for model compression', 'inputs': {'use_cache': True, 'dataset_type': 'regression', 'data_paths': {'train_data_path': './dataset/knowledge_distillation/text_matching_data/train.tsv', 'valid_data_path': './dataset/knowledge_distillation/text_matching_data/valid.tsv', 'test_data_path': './dataset/knowledge_distillation/text_matching_data/test.tsv', 'pre_trained_emb': 'dataset/GloVe/glove.840B.300d.txt'}, 'add_start_end_for_seq': True, 'file_header': {'query_text': 0, 'passage_text': 1, 'label_score': 2}, 'predict_file_header': {'query_text': 0, 'passage_text': 1}, 'model_inputs': {'query': ['query_text'], 'passage': ['passage_text']}, 'target': ['label_score']}, 'outputs': {'save_base_dir': './models/kdtm_match_linearAttn/', 'model_name': 'model.nb', 'train_log_name': 'train.log', 'test_log_name': 'test.log', 'predict_log_name': 'predict.log', 'predict_fields': ['prediction'], 'predict_output_name': 'predict.tsv', 'cache_dir': '.cache.kdtm_match_linearAttn/'}, 'training_params': {'vocabulary': {'min_word_frequency': 1}, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.2, 'momentum': 0.9, 'nesterov': True}}, 'lr_decay': 0.95, 'minimum_lr': 0.005, 'epoch_start_lr_decay': 1, 'use_gpu': True, 'batch_size': 128, 'batch_num_to_show_results': 100, 'max_epoch': 10, 'valid_times_per_epoch': 2, 'max_lengths': {'query': 30, 'passage': 200}}, 'architecture': [{'layer': 'Embedding', 'conf': {'word': {'cols': ['query_text', 'passage_text'], 'dim': 300}}}, {'layer_id': 'query_dropout', 'layer': 'Dropout', 'conf': {'dropout': 0.3}, 'inputs': ['query']}, {'layer_id': 'passage_dropout', 'layer': 'Dropout', 'conf': {'dropout': 0.3}, 'inputs': ['passage']}, {'layer_id': 'query_1', 'layer': 'BiLSTM', 'conf': {'hidden_dim': 128, 'dropout': 0.3, 'num_layers': 3}, 'inputs': ['query_dropout']}, {'layer_id': 'passage_matched', 'layer': 'MatchAttention', 'conf': {}, 'inputs': ['passage_dropout', 'query_dropout']}, {'layer_id': 'passage_combined', 'layer': 'Combination', 'conf': {'operations': ['origin']}, 'inputs': ['passage_dropout', 'passage_matched']}, {'layer_id': 'passage_1', 'layer': 'BiLSTM', 'conf': {'hidden_dim': 128, 'dropout': 0.3, 'num_layers': 3}, 'inputs': ['passage_combined']}, {'layer_id': 'query_linear_att', 'layer': 'LinearAttention', 'conf': {'attention_weight_dim': 256, 'keep_dim': False}, 'inputs': ['query_1']}, {'layer_id': 'passage_linear_att', 'layer': 'LinearAttention', 'conf': {'attention_weight_dim': 256, 'keep_dim': False}, 'inputs': ['passage_1']}, {'layer_id': 'comb', 'layer': 'Combination', 'conf': {'operations': ['origin']}, 'inputs': ['query_linear_att', 'passage_linear_att']}, {'layer_id': 'linear', 'layer': 'Linear', 'conf': {'hidden_dim': [512], 'activation': 'PReLU', 'batch_norm': True, 'last_hidden_activation': True}, 'inputs': ['comb']}, {'output_layer_flag': True, 'layer_id': 'output', 'layer': 'Linear', 'conf': {'hidden_dim': [1], 'activation': 'Sigmoid', 'last_hidden_activation': True, 'last_hidden_softmax': False}, 'inputs': ['linear']}], 'loss': {'losses': [{'type': 'MSELoss', 'conf': {}, 'inputs': ['output', 'label_score']}]}, 'metrics': ['RMSE', 'MSE']}
2019-05-26 07:10:46,083 DEBUG ModelConf.py __init__ 50: tool_version: 1.1.0
2019-05-26 07:10:46,083 DEBUG ModelConf.py __init__ 50: language: english
2019-05-26 07:10:46,083 DEBUG ModelConf.py __init__ 50: problem_type: regression
2019-05-26 07:10:46,083 DEBUG ModelConf.py __init__ 50: use_cache: True
2019-05-26 07:10:46,083 DEBUG ModelConf.py __init__ 50: save_base_dir: ./models/kdtm_match_linearAttn/
2019-05-26 07:10:46,083 DEBUG ModelConf.py __init__ 50: log_dir: ./models/kdtm_match_linearAttn/
2019-05-26 07:10:46,083 DEBUG ModelConf.py __init__ 50: predict_fields: ['prediction']
2019-05-26 07:10:46,084 DEBUG ModelConf.py __init__ 50: model_save_path: ./models/kdtm_match_linearAttn/model.nb
2019-05-26 07:10:46,084 DEBUG ModelConf.py __init__ 50: train_data_path: ./dataset/knowledge_distillation/text_matching_data/train.tsv
2019-05-26 07:10:46,084 DEBUG ModelConf.py __init__ 50: valid_data_path: ./dataset/knowledge_distillation/text_matching_data/valid.tsv
2019-05-26 07:10:46,084 DEBUG ModelConf.py __init__ 50: test_data_path: ./dataset/knowledge_distillation/text_matching_data/test.tsv
2019-05-26 07:10:46,084 DEBUG ModelConf.py __init__ 50: file_columns: {'query_text': 0, 'passage_text': 1, 'label_score': 2}
2019-05-26 07:10:46,084 DEBUG ModelConf.py __init__ 50: answer_column_name: ['label_score']
2019-05-26 07:10:46,084 DEBUG ModelConf.py __init__ 50: input_types: {'word': {'cols': ['query_text', 'passage_text'], 'dim': 300}}
2019-05-26 07:10:46,084 DEBUG ModelConf.py __init__ 50: extra_feature: False
2019-05-26 07:10:46,084 DEBUG ModelConf.py __init__ 50: object_inputs: {'query': ['query_text'], 'passage': ['passage_text']}
2019-05-26 07:10:46,084 DEBUG ModelConf.py __init__ 50: object_inputs_names: ['query', 'passage']
2019-05-26 07:10:46,084 DEBUG ModelConf.py __init__ 50: max_vocabulary: 800000
2019-05-26 07:10:46,084 DEBUG ModelConf.py __init__ 50: min_word_frequency: 1
2019-05-26 07:10:46,084 DEBUG ModelConf.py __init__ 50: file_with_col_header: False
2019-05-26 07:10:46,084 DEBUG ModelConf.py __init__ 50: add_start_end_for_seq: True
2019-05-26 07:10:46,085 DEBUG ModelConf.py __init__ 50: pretrained_emb_path: dataset/GloVe/glove.840B.300d.txt
2019-05-26 07:10:46,085 DEBUG ModelConf.py __init__ 50: involve_all_words_in_pretrained_emb: False
2019-05-26 07:10:46,085 DEBUG ModelConf.py __init__ 50: pretrained_emb_type: glove
2019-05-26 07:10:46,085 DEBUG ModelConf.py __init__ 50: pretrained_emb_binary_or_text: text
2019-05-26 07:10:46,085 DEBUG ModelConf.py __init__ 50: pretrained_emb_dim: 300
2019-05-26 07:10:46,085 DEBUG ModelConf.py __init__ 50: problem_path: ./models/kdtm_match_linearAttn/necessary_cache/problem.pkl
2019-05-26 07:10:46,085 DEBUG ModelConf.py __init__ 50: training_params: {'vocabulary': {'min_word_frequency': 1}, 'optimizer': {'name': 'SGD', 'params': {'lr': 0.2, 'momentum': 0.9, 'nesterov': True}}, 'lr_decay': 0.95, 'minimum_lr': 0.005, 'epoch_start_lr_decay': 1, 'use_gpu': True, 'batch_size': 128, 'batch_num_to_show_results': 100, 'max_epoch': 10, 'valid_times_per_epoch': 2, 'max_lengths': {'query': 30, 'passage': 200}}
2019-05-26 07:10:46,085 DEBUG ModelConf.py __init__ 50: batch_size_each_gpu: 128
2019-05-26 07:10:46,085 DEBUG ModelConf.py __init__ 50: lr_decay: 0.95
2019-05-26 07:10:46,085 DEBUG ModelConf.py __init__ 50: minimum_lr: 0.005
2019-05-26 07:10:46,085 DEBUG ModelConf.py __init__ 50: epoch_start_lr_decay: 1
2019-05-26 07:10:46,085 DEBUG ModelConf.py __init__ 50: max_epoch: 10
2019-05-26 07:10:46,085 DEBUG ModelConf.py __init__ 50: valid_times_per_epoch: 2
2019-05-26 07:10:46,085 DEBUG ModelConf.py __init__ 50: batch_num_to_show_results: 100
2019-05-26 07:10:46,085 DEBUG ModelConf.py __init__ 50: max_lengths: {'query': 30, 'passage': 200}
2019-05-26 07:10:46,086 DEBUG ModelConf.py __init__ 50: fixed_lengths: None
2019-05-26 07:10:46,086 DEBUG ModelConf.py __init__ 50: batch_size_total: 128
2019-05-26 07:10:46,086 DEBUG ModelConf.py __init__ 50: cpu_num_workers: -1
2019-05-26 07:10:46,086 DEBUG ModelConf.py __init__ 50: _ModelConf__text_preprocessing: []
2019-05-26 07:10:46,086 DEBUG ModelConf.py __init__ 50: DBC2SBC: False
2019-05-26 07:10:46,086 DEBUG ModelConf.py __init__ 50: unicode_fix: False
2019-05-26 07:10:46,086 DEBUG ModelConf.py __init__ 50: remove_stopwords: False
2019-05-26 07:10:46,086 DEBUG ModelConf.py __init__ 50: tokenizer: nltk
2019-05-26 07:10:46,086 DEBUG ModelConf.py __init__ 50: architecture: [{'layer': 'Embedding', 'conf': {'word': {'cols': ['query_text', 'passage_text'], 'dim': 300}}}, {'layer_id': 'query_dropout', 'layer': 'Dropout', 'conf': {'dropout': 0.3}, 'inputs': ['query']}, {'layer_id': 'passage_dropout', 'layer': 'Dropout', 'conf': {'dropout': 0.3}, 'inputs': ['passage']}, {'layer_id': 'query_1', 'layer': 'BiLSTM', 'conf': {'hidden_dim': 128, 'dropout': 0.3, 'num_layers': 3}, 'inputs': ['query_dropout']}, {'layer_id': 'passage_matched', 'layer': 'MatchAttention', 'conf': {}, 'inputs': ['passage_dropout', 'query_dropout']}, {'layer_id': 'passage_combined', 'layer': 'Combination', 'conf': {'operations': ['origin']}, 'inputs': ['passage_dropout', 'passage_matched']}, {'layer_id': 'passage_1', 'layer': 'BiLSTM', 'conf': {'hidden_dim': 128, 'dropout': 0.3, 'num_layers': 3}, 'inputs': ['passage_combined']}, {'layer_id': 'query_linear_att', 'layer': 'LinearAttention', 'conf': {'attention_weight_dim': 256, 'keep_dim': False}, 'inputs': ['query_1']}, {'layer_id': 'passage_linear_att', 'layer': 'LinearAttention', 'conf': {'attention_weight_dim': 256, 'keep_dim': False}, 'inputs': ['passage_1']}, {'layer_id': 'comb', 'layer': 'Combination', 'conf': {'operations': ['origin']}, 'inputs': ['query_linear_att', 'passage_linear_att']}, {'layer_id': 'linear', 'layer': 'Linear', 'conf': {'hidden_dim': [512], 'activation': 'PReLU', 'batch_norm': True, 'last_hidden_activation': True}, 'inputs': ['comb']}, {'output_layer_flag': True, 'layer_id': 'output', 'layer': 'Linear', 'conf': {'hidden_dim': [1], 'activation': 'Sigmoid', 'last_hidden_activation': True, 'last_hidden_softmax': False}, 'inputs': ['linear']}]
2019-05-26 07:10:46,087 DEBUG ModelConf.py __init__ 50: output_layer_id: ['output']
2019-05-26 07:10:46,087 DEBUG ModelConf.py __init__ 50: min_sentence_len: 0
2019-05-26 07:10:46,087 DEBUG ModelConf.py __init__ 51: ================================================================================
2019-05-26 07:10:46,087 INFO train.py main 103: Found cache that is appliable to current configuration...
2019-05-26 07:10:46,150 DEBUG common_utils.py load_from_pkl 41: .cache.kdtm_match_linearAttn/problem.pkl loaded!
2019-05-26 07:10:46,150 DEBUG problem.py load_problem 808: Problem loaded
2019-05-26 07:10:46,347 DEBUG common_utils.py load_from_pkl 41: .cache.kdtm_match_linearAttn/emb.pkl loaded!
2019-05-26 07:10:46,431 INFO train.py main 137: Cache loaded!
2019-05-26 07:10:46,431 DEBUG train.py main 177: Prepare dir: ./autotest/models/kdtm_match_linearAttn/necessary_cache/
2019-05-26 07:10:46,432 INFO common_utils.py prepare_dir 204: Clear dir ./autotest/models/kdtm_match_linearAttn/necessary_cache/...
2019-05-26 07:10:46,434 DEBUG train.py main 181: Problem .cache.kdtm_match_linearAttn/problem.pkl is backed up to ./autotest/models/kdtm_match_linearAttn/necessary_cache/
2019-05-26 07:10:46,535 DEBUG Model.py get_conf 103: Layer id: embedding; name: Embedding; input_dims: None; input_ranks: [2]; output_dim: [-1, -1, 300]; output_rank: 3
2019-05-26 07:10:46,902 DEBUG Model.py get_conf 103: Layer id: query_dropout; name: Dropout; input_dims: [[-1, -1, 300]]; input_ranks: [3]; output_dim: [-1, -1, 300]; output_rank: 3
2019-05-26 07:10:46,902 DEBUG Model.py get_conf 103: Layer id: passage_dropout; name: Dropout; input_dims: [[-1, -1, 300]]; input_ranks: [3]; output_dim: [-1, -1, 300]; output_rank: 3
2019-05-26 07:10:46,902 DEBUG Model.py get_conf 103: Layer id: query_1; name: BiLSTM; input_dims: [[-1, -1, 300]]; input_ranks: [3]; output_dim: [-1, -1, 256]; output_rank: 3
2019-05-26 07:10:46,916 DEBUG Model.py get_conf 103: Layer id: passage_matched; name: MatchAttention; input_dims: [[-1, -1, 300], [-1, -1, 300]]; input_ranks: [3, 3]; output_dim: [-1, -1, 300]; output_rank: 3
2019-05-26 07:10:46,917 DEBUG Model.py get_conf 103: Layer id: passage_combined; name: Combination; input_dims: [[-1, -1, 300], [-1, -1, 300]]; input_ranks: [3, 3]; output_dim: [-1, -1, 600]; output_rank: 3
2019-05-26 07:10:46,918 WARNING Combination.py __init__ 90: The length Combination layer returns is the length of first input
2019-05-26 07:10:46,918 DEBUG Model.py get_conf 103: Layer id: passage_1; name: BiLSTM; input_dims: [[-1, -1, 600]]; input_ranks: [3]; output_dim: [-1, -1, 256]; output_rank: 3
2019-05-26 07:10:46,934 DEBUG Model.py get_conf 103: Layer id: query_linear_att; name: LinearAttention; input_dims: [[-1, -1, 256]]; input_ranks: [3]; output_dim: [-1, 256]; output_rank: 2
2019-05-26 07:10:46,935 DEBUG Model.py get_conf 103: Layer id: passage_linear_att; name: LinearAttention; input_dims: [[-1, -1, 256]]; input_ranks: [3]; output_dim: [-1, 256]; output_rank: 2
2019-05-26 07:10:46,935 DEBUG Model.py get_conf 103: Layer id: comb; name: Combination; input_dims: [[-1, 256], [-1, 256]]; input_ranks: [2, 2]; output_dim: [-1, 512]; output_rank: 2
2019-05-26 07:10:46,935 WARNING Combination.py __init__ 90: The length Combination layer returns is the length of first input
2019-05-26 07:10:46,935 DEBUG Model.py get_conf 103: Layer id: linear; name: Linear; input_dims: [[-1, 512]]; input_ranks: [2]; output_dim: [-1, 512]; output_rank: 2
2019-05-26 07:10:46,939 DEBUG Model.py get_conf 103: Layer id: output; name: Linear; input_dims: [[-1, 512]]; input_ranks: [2]; output_dim: [-1, 1]; output_rank: 2
2019-05-26 07:10:46,939 DEBUG Model.py __init__ 243: Layer dependencies: {'embedding': set(), 'query_dropout': set(), 'passage_dropout': set(), 'query_1': {'query_dropout'}, 'passage_matched': {'query_dropout', 'passage_dropout'}, 'passage_combined': {'passage_dropout', 'passage_matched'}, 'passage_1': {'passage_combined'}, 'query_linear_att': {'query_1'}, 'passage_linear_att': {'passage_1'}, 'comb': {'passage_linear_att', 'query_linear_att'}, 'linear': {'comb'}, 'output': {'linear'}}
2019-05-26 07:10:46,939 DEBUG Model.py get_topological_sequence 326: Topological sequence of nodes: query_dropout,passage_dropout,query_1,passage_matched,passage_combined,passage_1,query_linear_att,passage_linear_att,comb,linear,output
2019-05-26 07:10:51,053 INFO LearningMachine.py __init__ 37: DataParallel(
  (module): Model(
    (layers): ModuleDict(
      (embedding): Embedding()
      (query_dropout): Dropout(
        (dropout_layer): Dropout(p=0.3)
      )
      (passage_dropout): Dropout(
        (dropout_layer): Dropout(p=0.3)
      )
      (query_1): BiLSTM(
        (lstm): LSTM(300, 128, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
      )
      (passage_matched): MatchAttention(
        (linear): Linear(in_features=300, out_features=300, bias=True)
        (relu): ReLU()
        (softmax): Softmax()
      )
      (passage_combined): Combination()
      (passage_1): BiLSTM(
        (lstm): LSTM(600, 128, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
      )
      (query_linear_att): LinearAttention()
      (passage_linear_att): LinearAttention()
      (comb): Combination()
      (linear): Linear(
        (linear): Sequential(
          (linear_0): Linear(in_features=512, out_features=512, bias=True)
          (batch_norm_1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (linear_activate_2): PReLU(num_parameters=1)
        )
      )
      (output): Linear(
        (linear): Sequential(
          (linear_0): Linear(in_features=512, out_features=1, bias=True)
          (batch_norm_1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (linear_activate_2): Sigmoid()
        )
      )
    )
  )
)
2019-05-26 07:10:51,054 INFO LearningMachine.py __init__ 39: Total trainable parameters: 3123904
2019-05-26 07:10:51,054 INFO LearningMachine.py __init__ 40: Model built!
2019-05-26 07:10:55,417 INFO problem.py encode 684: ./autotest/dataset/knowledge_distillation/text_matching_data/train_autotest.tsv: 10000 legal samples, 0 illegal samples
2019-05-26 07:10:59,677 INFO problem.py encode 684: ./autotest/dataset/knowledge_distillation/text_matching_data/valid.tsv: 2400 legal samples, 0 illegal samples
2019-05-26 07:11:03,874 INFO problem.py encode 684: ./autotest/dataset/knowledge_distillation/text_matching_data/test.tsv: 2400 legal samples, 0 illegal samples
2019-05-26 07:11:03,875 INFO LearningMachine.py train 130: Training: Epoch 1
2019-05-26 07:11:03,875 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:11:04,666 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:11:04,673 INFO LearningMachine.py train 148: There are 79 batches during an epoch; validation are conducted every 39 batch
2019-05-26 07:11:21,132 INFO LearningMachine.py train 300: Valid & Test : Epoch 1
2019-05-26 07:11:21,133 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:11:21,133 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:11:21,174 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:11:23,222 INFO LearningMachine.py evaluate 578: Epoch 1, valid RMSE: 0.372579; MSE: 0.138815 loss: 0.139185
2019-05-26 07:11:23,223 INFO LearningMachine.py evaluate 586: Cur result 0.372579 is better than previous best result None, renew the best model now...
2019-05-26 07:11:24,428 INFO LearningMachine.py evaluate 601: Best model saved to ./autotest/models/kdtm_match_linearAttn/model.nb
2019-05-26 07:11:24,429 INFO LearningMachine.py evaluate 386: Starting test ...
2019-05-26 07:11:24,430 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:11:24,488 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:11:26,302 INFO LearningMachine.py evaluate 578: Epoch 1, test RMSE: 0.512586; MSE: 0.262744 loss: 0.264210
2019-05-26 07:11:43,423 INFO LearningMachine.py train 300: Valid & Test : Epoch 1
2019-05-26 07:11:43,423 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:11:43,423 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:11:43,457 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:11:45,107 INFO LearningMachine.py evaluate 578: Epoch 1, valid RMSE: 0.386733; MSE: 0.149562 loss: 0.150385
2019-05-26 07:11:45,107 INFO LearningMachine.py evaluate 604: Cur result 0.386733 is no better than previous best result 0.372579
2019-05-26 07:11:45,113 INFO LearningMachine.py train 130: Training: Epoch 2
2019-05-26 07:11:45,114 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:11:45,816 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:11:45,824 INFO LearningMachine.py train 148: There are 79 batches during an epoch; validation are conducted every 39 batch
2019-05-26 07:11:57,318 INFO LearningMachine.py train 292: Epoch 2 batch idx: 21; lr: 0.190000; since last log, loss=0.121622; RMSE: 0.348744; MSE: 0.121622
2019-05-26 07:12:06,557 INFO LearningMachine.py train 300: Valid & Test : Epoch 2
2019-05-26 07:12:06,558 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:12:06,558 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:12:06,580 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:12:08,796 INFO LearningMachine.py evaluate 578: Epoch 2, valid RMSE: 0.350678; MSE: 0.122975 loss: 0.123066
2019-05-26 07:12:08,796 INFO LearningMachine.py evaluate 586: Cur result 0.350678 is better than previous best result 0.372579, renew the best model now...
2019-05-26 07:12:10,005 INFO LearningMachine.py evaluate 601: Best model saved to ./autotest/models/kdtm_match_linearAttn/model.nb
2019-05-26 07:12:10,006 INFO LearningMachine.py evaluate 386: Starting test ...
2019-05-26 07:12:10,007 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:12:10,031 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:12:12,354 INFO LearningMachine.py evaluate 578: Epoch 2, test RMSE: 0.486810; MSE: 0.236984 loss: 0.237583
2019-05-26 07:12:33,471 INFO LearningMachine.py train 300: Valid & Test : Epoch 2
2019-05-26 07:12:33,471 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:12:33,472 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:12:33,494 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:12:35,726 INFO LearningMachine.py evaluate 578: Epoch 2, valid RMSE: 0.361946; MSE: 0.131005 loss: 0.131649
2019-05-26 07:12:35,726 INFO LearningMachine.py evaluate 604: Cur result 0.361946 is no better than previous best result 0.350678
2019-05-26 07:12:35,729 INFO LearningMachine.py train 130: Training: Epoch 3
2019-05-26 07:12:35,729 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:12:36,482 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:12:36,490 INFO LearningMachine.py train 148: There are 79 batches during an epoch; validation are conducted every 39 batch
2019-05-26 07:12:57,459 INFO LearningMachine.py train 300: Valid & Test : Epoch 3
2019-05-26 07:12:57,459 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:12:57,460 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:12:57,483 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:12:59,978 INFO LearningMachine.py evaluate 578: Epoch 3, valid RMSE: 0.355469; MSE: 0.126358 loss: 0.126749
2019-05-26 07:12:59,979 INFO LearningMachine.py evaluate 604: Cur result 0.355469 is no better than previous best result 0.350678
2019-05-26 07:13:01,728 INFO LearningMachine.py train 292: Epoch 3 batch idx: 42; lr: 0.180500; since last log, loss=0.116460; RMSE: 0.341262; MSE: 0.116460
2019-05-26 07:13:18,775 INFO LearningMachine.py train 300: Valid & Test : Epoch 3
2019-05-26 07:13:18,776 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:13:18,776 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:13:18,807 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:13:21,314 INFO LearningMachine.py evaluate 578: Epoch 3, valid RMSE: 0.350437; MSE: 0.122806 loss: 0.123118
2019-05-26 07:13:21,314 INFO LearningMachine.py evaluate 586: Cur result 0.350437 is better than previous best result 0.350678, renew the best model now...
2019-05-26 07:13:22,457 INFO LearningMachine.py evaluate 601: Best model saved to ./autotest/models/kdtm_match_linearAttn/model.nb
2019-05-26 07:13:22,458 INFO LearningMachine.py evaluate 386: Starting test ...
2019-05-26 07:13:22,459 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:13:22,493 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:13:24,896 INFO LearningMachine.py evaluate 578: Epoch 3, test RMSE: 0.486684; MSE: 0.236861 loss: 0.238144
2019-05-26 07:13:24,899 INFO LearningMachine.py train 130: Training: Epoch 4
2019-05-26 07:13:24,900 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:13:25,633 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:13:25,641 INFO LearningMachine.py train 148: There are 79 batches during an epoch; validation are conducted every 39 batch
2019-05-26 07:13:46,244 INFO LearningMachine.py train 300: Valid & Test : Epoch 4
2019-05-26 07:13:46,245 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:13:46,245 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:13:46,267 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:13:48,704 INFO LearningMachine.py evaluate 578: Epoch 4, valid RMSE: 0.352884; MSE: 0.124527 loss: 0.124995
2019-05-26 07:13:48,704 INFO LearningMachine.py evaluate 604: Cur result 0.352884 is no better than previous best result 0.350437
2019-05-26 07:14:01,597 INFO LearningMachine.py train 292: Epoch 4 batch idx: 63; lr: 0.171475; since last log, loss=0.113478; RMSE: 0.336865; MSE: 0.113478
2019-05-26 07:14:09,458 INFO LearningMachine.py train 300: Valid & Test : Epoch 4
2019-05-26 07:14:09,459 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:14:09,460 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:14:09,501 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:14:11,728 INFO LearningMachine.py evaluate 578: Epoch 4, valid RMSE: 0.350751; MSE: 0.123026 loss: 0.123474
2019-05-26 07:14:11,729 INFO LearningMachine.py evaluate 604: Cur result 0.350751 is no better than previous best result 0.350437
2019-05-26 07:14:11,732 INFO LearningMachine.py train 130: Training: Epoch 5
2019-05-26 07:14:11,732 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:14:12,448 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:14:12,456 INFO LearningMachine.py train 148: There are 79 batches during an epoch; validation are conducted every 39 batch
2019-05-26 07:14:32,614 INFO LearningMachine.py train 300: Valid & Test : Epoch 5
2019-05-26 07:14:32,614 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:14:32,614 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:14:32,637 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:14:34,561 INFO LearningMachine.py evaluate 578: Epoch 5, valid RMSE: 0.345827; MSE: 0.119596 loss: 0.119811
2019-05-26 07:14:34,561 INFO LearningMachine.py evaluate 586: Cur result 0.345827 is better than previous best result 0.350437, renew the best model now...
2019-05-26 07:14:35,768 INFO LearningMachine.py evaluate 601: Best model saved to ./autotest/models/kdtm_match_linearAttn/model.nb
2019-05-26 07:14:35,769 INFO LearningMachine.py evaluate 386: Starting test ...
2019-05-26 07:14:35,769 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:14:35,794 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:14:38,014 INFO LearningMachine.py evaluate 578: Epoch 5, test RMSE: 0.480142; MSE: 0.230536 loss: 0.231359
2019-05-26 07:14:58,000 INFO LearningMachine.py train 300: Valid & Test : Epoch 5
2019-05-26 07:14:58,000 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:14:58,001 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:14:58,022 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:15:00,304 INFO LearningMachine.py evaluate 578: Epoch 5, valid RMSE: 0.344188; MSE: 0.118465 loss: 0.118692
2019-05-26 07:15:00,304 INFO LearningMachine.py evaluate 586: Cur result 0.344188 is better than previous best result 0.345827, renew the best model now...
2019-05-26 07:15:01,522 INFO LearningMachine.py evaluate 601: Best model saved to ./autotest/models/kdtm_match_linearAttn/model.nb
2019-05-26 07:15:01,523 INFO LearningMachine.py evaluate 386: Starting test ...
2019-05-26 07:15:01,524 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:15:01,558 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:15:03,787 INFO LearningMachine.py evaluate 578: Epoch 5, test RMSE: 0.483306; MSE: 0.233585 loss: 0.233706
2019-05-26 07:15:03,789 INFO LearningMachine.py train 130: Training: Epoch 6
2019-05-26 07:15:03,789 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:15:04,337 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:15:04,345 INFO LearningMachine.py train 148: There are 79 batches during an epoch; validation are conducted every 39 batch
2019-05-26 07:15:07,515 INFO LearningMachine.py train 292: Epoch 6 batch idx: 5; lr: 0.154756; since last log, loss=0.111601; RMSE: 0.334067; MSE: 0.111601
2019-05-26 07:15:26,180 INFO LearningMachine.py train 300: Valid & Test : Epoch 6
2019-05-26 07:15:26,180 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:15:26,182 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:15:26,205 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:15:28,506 INFO LearningMachine.py evaluate 578: Epoch 6, valid RMSE: 0.356506; MSE: 0.127097 loss: 0.127545
2019-05-26 07:15:28,506 INFO LearningMachine.py evaluate 604: Cur result 0.356506 is no better than previous best result 0.344188
2019-05-26 07:15:49,328 INFO LearningMachine.py train 300: Valid & Test : Epoch 6
2019-05-26 07:15:49,328 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:15:49,329 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:15:49,352 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:15:51,957 INFO LearningMachine.py evaluate 578: Epoch 6, valid RMSE: 0.360018; MSE: 0.129613 loss: 0.130197
2019-05-26 07:15:51,958 INFO LearningMachine.py evaluate 604: Cur result 0.360018 is no better than previous best result 0.344188
2019-05-26 07:15:51,960 INFO LearningMachine.py train 130: Training: Epoch 7
2019-05-26 07:15:51,960 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:15:52,731 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:15:52,739 INFO LearningMachine.py train 148: There are 79 batches during an epoch; validation are conducted every 39 batch
2019-05-26 07:16:05,342 INFO LearningMachine.py train 292: Epoch 7 batch idx: 26; lr: 0.147018; since last log, loss=0.101049; RMSE: 0.317882; MSE: 0.101049
2019-05-26 07:16:11,777 INFO LearningMachine.py train 300: Valid & Test : Epoch 7
2019-05-26 07:16:11,777 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:16:11,778 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:16:11,811 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:16:13,384 INFO LearningMachine.py evaluate 578: Epoch 7, valid RMSE: 0.346324; MSE: 0.119940 loss: 0.120187
2019-05-26 07:16:13,385 INFO LearningMachine.py evaluate 604: Cur result 0.346324 is no better than previous best result 0.344188
2019-05-26 07:16:29,548 INFO LearningMachine.py train 300: Valid & Test : Epoch 7
2019-05-26 07:16:29,549 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:16:29,550 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:16:29,590 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:16:31,417 INFO LearningMachine.py evaluate 578: Epoch 7, valid RMSE: 0.349279; MSE: 0.121996 loss: 0.122045
2019-05-26 07:16:31,418 INFO LearningMachine.py evaluate 604: Cur result 0.349279 is no better than previous best result 0.344188
2019-05-26 07:16:31,421 INFO LearningMachine.py train 130: Training: Epoch 8
2019-05-26 07:16:31,421 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:16:31,966 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:16:31,973 INFO LearningMachine.py train 148: There are 79 batches during an epoch; validation are conducted every 39 batch
2019-05-26 07:16:50,151 INFO LearningMachine.py train 300: Valid & Test : Epoch 8
2019-05-26 07:16:50,152 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:16:50,152 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:16:50,180 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:16:51,905 INFO LearningMachine.py evaluate 578: Epoch 8, valid RMSE: 0.358624; MSE: 0.128611 loss: 0.128651
2019-05-26 07:16:51,905 INFO LearningMachine.py evaluate 604: Cur result 0.358624 is no better than previous best result 0.344188
2019-05-26 07:16:55,756 INFO LearningMachine.py train 292: Epoch 8 batch idx: 47; lr: 0.139667; since last log, loss=0.097757; RMSE: 0.312661; MSE: 0.097757
2019-05-26 07:17:08,861 INFO LearningMachine.py train 300: Valid & Test : Epoch 8
2019-05-26 07:17:08,861 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:17:08,862 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:17:08,883 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:17:10,919 INFO LearningMachine.py evaluate 578: Epoch 8, valid RMSE: 0.347831; MSE: 0.120986 loss: 0.120925
2019-05-26 07:17:10,920 INFO LearningMachine.py evaluate 604: Cur result 0.347831 is no better than previous best result 0.344188
2019-05-26 07:17:10,923 INFO LearningMachine.py train 130: Training: Epoch 9
2019-05-26 07:17:10,923 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:17:11,559 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:17:11,566 INFO LearningMachine.py train 148: There are 79 batches during an epoch; validation are conducted every 39 batch
2019-05-26 07:17:27,458 INFO LearningMachine.py train 300: Valid & Test : Epoch 9
2019-05-26 07:17:27,459 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:17:27,459 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:17:27,485 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:17:29,220 INFO LearningMachine.py evaluate 578: Epoch 9, valid RMSE: 0.368577; MSE: 0.135849 loss: 0.136689
2019-05-26 07:17:29,220 INFO LearningMachine.py evaluate 604: Cur result 0.368577 is no better than previous best result 0.344188
2019-05-26 07:17:42,093 INFO LearningMachine.py train 292: Epoch 9 batch idx: 68; lr: 0.132684; since last log, loss=0.096751; RMSE: 0.311048; MSE: 0.096751
2019-05-26 07:17:45,844 INFO LearningMachine.py train 300: Valid & Test : Epoch 9
2019-05-26 07:17:45,845 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:17:45,845 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:17:45,869 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:17:47,735 INFO LearningMachine.py evaluate 578: Epoch 9, valid RMSE: 0.351398; MSE: 0.123480 loss: 0.123761
2019-05-26 07:17:47,735 INFO LearningMachine.py evaluate 604: Cur result 0.351398 is no better than previous best result 0.344188
2019-05-26 07:17:47,738 INFO LearningMachine.py train 130: Training: Epoch 10
2019-05-26 07:17:47,738 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:17:48,410 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:17:48,418 INFO LearningMachine.py train 148: There are 79 batches during an epoch; validation are conducted every 39 batch
2019-05-26 07:18:06,628 INFO LearningMachine.py train 300: Valid & Test : Epoch 10
2019-05-26 07:18:06,629 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:18:06,629 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:18:06,652 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:18:08,581 INFO LearningMachine.py evaluate 578: Epoch 10, valid RMSE: 0.356379; MSE: 0.127006 loss: 0.127581
2019-05-26 07:18:08,581 INFO LearningMachine.py evaluate 604: Cur result 0.356379 is no better than previous best result 0.344188
2019-05-26 07:18:25,109 INFO LearningMachine.py train 300: Valid & Test : Epoch 10
2019-05-26 07:18:25,110 INFO LearningMachine.py evaluate 386: Starting valid ...
2019-05-26 07:18:25,110 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:18:25,136 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:18:27,081 INFO LearningMachine.py evaluate 578: Epoch 10, valid RMSE: 0.349616; MSE: 0.122231 loss: 0.122360
2019-05-26 07:18:27,082 INFO LearningMachine.py evaluate 604: Cur result 0.349616 is no better than previous best result 0.344188
2019-05-26 07:18:27,485 INFO LearningMachine.py load_model 751: Model ./autotest/models/kdtm_match_linearAttn/model.nb loaded!
2019-05-26 07:18:27,485 INFO LearningMachine.py load_model 752: Total trainable parameters: 3123904
2019-05-26 07:18:27,485 INFO train.py main 238: Testing the best model saved at ./autotest/models/kdtm_match_linearAttn/model.nb, with ./autotest/dataset/knowledge_distillation/text_matching_data/test.tsv
2019-05-26 07:18:30,291 INFO problem.py encode 684: ./autotest/dataset/knowledge_distillation/text_matching_data/test.tsv: 2400 legal samples, 0 illegal samples
2019-05-26 07:18:30,291 INFO LearningMachine.py evaluate 386: Starting test ...
2019-05-26 07:18:30,291 INFO corpus_utils.py get_batches 235: Start making batches
2019-05-26 07:18:30,321 INFO corpus_utils.py get_batches 395: Batches got!
2019-05-26 07:18:32,332 INFO LearningMachine.py evaluate 580: test RMSE: 0.483306; MSE: 0.233585 loss: 0.233706
