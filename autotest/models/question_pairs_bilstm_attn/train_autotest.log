2019-05-27 00:22:00,419 DEBUG ModelConf.py load_from_file 129: Prepare dir for: ./autotest/models/question_pairs_bilstm_attn/predict.tsv
2019-05-27 00:22:00,632 INFO ModelConf.py load_from_file 353: Activating CPU mode
2019-05-27 00:22:00,633 DEBUG ModelConf.py __init__ 46: Print ModelConf below:
2019-05-27 00:22:00,633 DEBUG ModelConf.py __init__ 47: ================================================================================
2019-05-27 00:22:00,633 DEBUG ModelConf.py __init__ 51: phase: train
2019-05-27 00:22:00,633 DEBUG ModelConf.py __init__ 51: conf_path: autotest/conf/conf_question_pairs_bilstm_attn_autotest.json
2019-05-27 00:22:00,633 DEBUG ModelConf.py __init__ 51: params: Namespace(batch_size=None, cache_dir=None, conf_path='autotest/conf/conf_question_pairs_bilstm_attn_autotest.json', debug=False, disable_log_file=False, force=True, involve_all_words_in_pretrained_emb=False, learning_rate=None, log_dir=None, make_cache_only=False, max_epoch=None, mode='normal', model_save_dir=None, predict_output_path=None, pretrained_emb_binary_or_text='text', pretrained_emb_path=None, pretrained_emb_type='glove', pretrained_model_path=None, test_data_path=None, train_data_path=None, valid_data_path=None)
2019-05-27 00:22:00,633 DEBUG ModelConf.py __init__ 51: mode: normal
2019-05-27 00:22:00,633 DEBUG ModelConf.py __init__ 51: conf: {'license': 'Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT license.', 'tool_version': '1.1.0', 'model_description': 'This model is used for query query pairs task. It achieved accuracy: 0.878506; f1: 0.839425 on dev set', 'inputs': {'use_cache': True, 'dataset_type': 'classification', 'data_paths': {'train_data_path': './autotest/dataset/QQP/train_autotest.tsv', 'valid_data_path': './autotest/dataset/QQP/dev_autotest.tsv', 'test_data_path': './autotest/dataset/QQP/dev_autotest.tsv', 'pre_trained_emb': './dataset/GloVe/glove.840B.300d.txt'}, 'file_with_col_header': True, 'add_start_end_for_seq': True, 'file_header': {'id': 0, 'qid1': 1, 'qid2': 2, 'question1': 3, 'question2': 4, 'is_duplicate': 5}, 'model_inputs': {'sentence_1': ['question1'], 'sentence_2': ['question2']}, 'target': ['is_duplicate']}, 'outputs': {'save_base_dir': './autotest/models/question_pairs_bilstm_attn/', 'model_name': 'model.nb', 'train_log_name': 'train_autotest.log', 'test_log_name': 'test_autotest.log', 'predict_log_name': 'predict.log', 'predict_fields': ['prediction', 'confidence'], 'predict_output_name': 'predict.tsv', 'cache_dir': '.cache.QQP/'}, 'training_params': {'optimizer': {'name': 'Adam', 'params': {}}, 'vocabulary': {'min_word_frequency': 1}, 'lr_decay': 0.95, 'minimum_lr': 0.0001, 'epoch_start_lr_decay': 1, 'use_gpu': True, 'batch_size': 128, 'batch_num_to_show_results': 300, 'max_epoch': 25, 'valid_times_per_epoch': 2}, 'architecture': [{'layer': 'Embedding', 'conf': {'word': {'cols': ['question1', 'question2'], 'dim': 300, 'fix_weight': True}}}, {'layer_id': 's1_dropout', 'layer': 'Dropout', 'conf': {'dropout': 0.2}, 'inputs': ['sentence_1']}, {'layer_id': 's2_dropout', 'layer': 'Dropout', 'conf': {'dropout': 0.2}, 'inputs': ['sentence_2']}, {'layer_id': 's1_bilstm', 'layer': 'BiLSTM', 'conf': {'hidden_dim': 256, 'dropout': 0.2, 'num_layers': 2}, 'inputs': ['s1_dropout']}, {'layer_id': 's2_bilstm', 'layer': 's1_bilstm', 'inputs': ['s2_dropout']}, {'layer_id': 's1_attn', 'layer': 'Attention', 'conf': {}, 'inputs': ['s1_bilstm', 's2_bilstm']}, {'layer_id': 's2_attn', 'layer': 'Attention', 'conf': {}, 'inputs': ['s2_bilstm', 's1_bilstm']}, {'layer_id': 's1_comb', 'layer': 'Combination', 'conf': {'operations': ['origin']}, 'inputs': ['s1_bilstm', 's1_attn']}, {'layer_id': 's2_comb', 'layer': 'Combination', 'conf': {'operations': ['origin']}, 'inputs': ['s2_bilstm', 's2_attn']}, {'layer_id': 's1_bilstm2', 'layer': 'BiLSTM', 'conf': {'hidden_dim': 256, 'dropout': 0.2, 'num_layers': 2}, 'inputs': ['s1_comb']}, {'layer_id': 's2_bilstm2', 'layer': 'BiLSTM', 'conf': {'hidden_dim': 256, 'dropout': 0.2, 'num_layers': 2}, 'inputs': ['s2_comb']}, {'layer_id': 's1_pooling', 'layer': 'Pooling', 'conf': {'pool_axis': 1, 'pool_type': 'max'}, 'inputs': ['s1_bilstm2']}, {'layer_id': 's2_pooling', 'layer': 'Pooling', 'conf': {'pool_axis': 1, 'pool_type': 'max'}, 'inputs': ['s2_bilstm2']}, {'layer_id': 'sentence_comb', 'layer': 'Combination', 'conf': {'operations': ['origin', 'difference', 'dot_multiply']}, 'inputs': ['s1_pooling', 's2_pooling']}, {'output_layer_flag': True, 'layer_id': 'output', 'layer': 'Linear', 'conf': {'hidden_dim': [128, 2], 'activation': 'PReLU', 'batch_norm': True, 'last_hidden_activation': False}, 'inputs': ['sentence_comb']}], 'loss': {'losses': [{'type': 'CrossEntropyLoss', 'conf': {'size_average': True}, 'inputs': ['output', 'is_duplicate']}]}, 'metrics': ['accuracy', 'f1']}
2019-05-27 00:22:00,633 DEBUG ModelConf.py __init__ 51: tool_version: 1.1.0
2019-05-27 00:22:00,633 DEBUG ModelConf.py __init__ 51: language: english
2019-05-27 00:22:00,633 DEBUG ModelConf.py __init__ 51: problem_type: classification
2019-05-27 00:22:00,633 DEBUG ModelConf.py __init__ 51: tagging_scheme: None
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: use_cache: True
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: save_base_dir: ./autotest/models/question_pairs_bilstm_attn/
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: pretrained_model_path: None
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: previous_model_path: None
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: log_dir: ./autotest/models/question_pairs_bilstm_attn/
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: train_log_path: ./autotest/models/question_pairs_bilstm_attn/train_autotest.log
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: predict_output_path: ./autotest/models/question_pairs_bilstm_attn/predict.tsv
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: predict_fields: ['prediction', 'confidence']
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: model_save_path: ./autotest/models/question_pairs_bilstm_attn/model.nb
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: train_data_path: ./autotest/dataset/QQP/train_autotest.tsv
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: valid_data_path: ./autotest/dataset/QQP/dev_autotest.tsv
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: test_data_path: ./autotest/dataset/QQP/dev_autotest.tsv
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: file_columns: {'id': 0, 'qid1': 1, 'qid2': 2, 'question1': 3, 'question2': 4, 'is_duplicate': 5}
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: answer_column_name: ['is_duplicate']
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: input_types: {'word': {'cols': ['question1', 'question2'], 'dim': 300, 'fix_weight': True}}
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: extra_feature: False
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: object_inputs: {'sentence_1': ['question1'], 'sentence_2': ['question2']}
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: object_inputs_names: ['sentence_1', 'sentence_2']
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: max_vocabulary: 800000
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: min_word_frequency: 1
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: file_with_col_header: True
2019-05-27 00:22:00,634 DEBUG ModelConf.py __init__ 51: add_start_end_for_seq: True
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: pretrained_emb_path: ./dataset/GloVe/glove.840B.300d.txt
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: involve_all_words_in_pretrained_emb: False
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: pretrained_emb_type: glove
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: pretrained_emb_binary_or_text: text
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: pretrained_emb_dim: 300
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: cache_dir: .cache.QQP/
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: problem_path: .cache.QQP/problem.pkl
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: emb_pkl_path: .cache.QQP/emb.pkl
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: training_params: {'optimizer': {'name': 'Adam', 'params': {}}, 'vocabulary': {'min_word_frequency': 1}, 'lr_decay': 0.95, 'minimum_lr': 0.0001, 'epoch_start_lr_decay': 1, 'use_gpu': True, 'batch_size': 128, 'batch_num_to_show_results': 300, 'max_epoch': 25, 'valid_times_per_epoch': 2}
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: optimizer_name: Adam
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: optimizer_params: {}
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: clip_grad_norm_max_norm: 5
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: batch_size_each_gpu: 128
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: lr_decay: 0.95
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: minimum_lr: 0.0001
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: epoch_start_lr_decay: 1
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: max_epoch: 25
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: valid_times_per_epoch: 2
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: batch_num_to_show_results: 300
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: max_lengths: None
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: fixed_lengths: None
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: batch_size_total: 128
2019-05-27 00:22:00,635 DEBUG ModelConf.py __init__ 51: cpu_num_workers: -1
2019-05-27 00:22:00,636 DEBUG ModelConf.py __init__ 51: _ModelConf__text_preprocessing: []
2019-05-27 00:22:00,636 DEBUG ModelConf.py __init__ 51: DBC2SBC: False
2019-05-27 00:22:00,636 DEBUG ModelConf.py __init__ 51: unicode_fix: False
2019-05-27 00:22:00,636 DEBUG ModelConf.py __init__ 51: remove_stopwords: False
2019-05-27 00:22:00,636 DEBUG ModelConf.py __init__ 51: tokenizer: nltk
2019-05-27 00:22:00,636 DEBUG ModelConf.py __init__ 51: use_gpu: False
2019-05-27 00:22:00,636 DEBUG ModelConf.py __init__ 51: architecture: [{'layer': 'Embedding', 'conf': {'word': {'cols': ['question1', 'question2'], 'dim': 300, 'fix_weight': True}}}, {'layer_id': 's1_dropout', 'layer': 'Dropout', 'conf': {'dropout': 0.2}, 'inputs': ['sentence_1']}, {'layer_id': 's2_dropout', 'layer': 'Dropout', 'conf': {'dropout': 0.2}, 'inputs': ['sentence_2']}, {'layer_id': 's1_bilstm', 'layer': 'BiLSTM', 'conf': {'hidden_dim': 256, 'dropout': 0.2, 'num_layers': 2}, 'inputs': ['s1_dropout']}, {'layer_id': 's2_bilstm', 'layer': 's1_bilstm', 'inputs': ['s2_dropout']}, {'layer_id': 's1_attn', 'layer': 'Attention', 'conf': {}, 'inputs': ['s1_bilstm', 's2_bilstm']}, {'layer_id': 's2_attn', 'layer': 'Attention', 'conf': {}, 'inputs': ['s2_bilstm', 's1_bilstm']}, {'layer_id': 's1_comb', 'layer': 'Combination', 'conf': {'operations': ['origin']}, 'inputs': ['s1_bilstm', 's1_attn']}, {'layer_id': 's2_comb', 'layer': 'Combination', 'conf': {'operations': ['origin']}, 'inputs': ['s2_bilstm', 's2_attn']}, {'layer_id': 's1_bilstm2', 'layer': 'BiLSTM', 'conf': {'hidden_dim': 256, 'dropout': 0.2, 'num_layers': 2}, 'inputs': ['s1_comb']}, {'layer_id': 's2_bilstm2', 'layer': 'BiLSTM', 'conf': {'hidden_dim': 256, 'dropout': 0.2, 'num_layers': 2}, 'inputs': ['s2_comb']}, {'layer_id': 's1_pooling', 'layer': 'Pooling', 'conf': {'pool_axis': 1, 'pool_type': 'max'}, 'inputs': ['s1_bilstm2']}, {'layer_id': 's2_pooling', 'layer': 'Pooling', 'conf': {'pool_axis': 1, 'pool_type': 'max'}, 'inputs': ['s2_bilstm2']}, {'layer_id': 'sentence_comb', 'layer': 'Combination', 'conf': {'operations': ['origin', 'difference', 'dot_multiply']}, 'inputs': ['s1_pooling', 's2_pooling']}, {'output_layer_flag': True, 'layer_id': 'output', 'layer': 'Linear', 'conf': {'hidden_dim': [128, 2], 'activation': 'PReLU', 'batch_norm': True, 'last_hidden_activation': False}, 'inputs': ['sentence_comb']}]
2019-05-27 00:22:00,636 DEBUG ModelConf.py __init__ 51: output_layer_id: ['output']
2019-05-27 00:22:00,636 DEBUG ModelConf.py __init__ 51: min_sentence_len: 0
2019-05-27 00:22:00,636 DEBUG ModelConf.py __init__ 51: loss: {'losses': [{'type': 'CrossEntropyLoss', 'conf': {'size_average': True}, 'inputs': ['output', 'is_duplicate']}], 'multiLoss': False}
2019-05-27 00:22:00,636 DEBUG ModelConf.py __init__ 51: metrics: ['accuracy', 'f1']
2019-05-27 00:22:00,636 DEBUG ModelConf.py __init__ 51: metrics_post_check: set()
2019-05-27 00:22:00,636 DEBUG ModelConf.py __init__ 52: ================================================================================
2019-05-27 00:22:00,636 INFO train.py main 173: Preprocessing... Depending on your corpus size, this step may take a while.
2019-05-27 00:22:02,165 INFO problem.py build 295: Corpus imported: 8997 legal lines, 0 illegal lines.
2019-05-27 00:22:02,187 INFO problem.py build 300: 15075 types in word column
2019-05-27 00:22:02,187 INFO problem.py build 303: 2 types in target column
2019-05-27 00:22:02,188 DEBUG problem.py build 304: training data dict built
2019-05-27 00:22:02,188 INFO problem.py build 309: Getting pre-trained embeddings...
